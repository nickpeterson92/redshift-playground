# Redshift Migration & Data Sharing Architecture

A comprehensive AWS Redshift implementation showcasing migration strategies, serverless architectures, data sharing patterns, and advanced networking configurations with Network Load Balancer (NLB) for horizontal scaling.

## üöÄ Project Overview

This project demonstrates:
- **Primary**: Production-grade Redshift Serverless with data sharing
- **Optional**: Traditional Redshift cluster for initial data loading
- Horizontal scaling using Network Load Balancer (NLB)
- Read/write separation with producer/consumer pattern
- Cost optimization with auto-pause and right-sizing
- Real-world airline data model with star schema design

## Project Structure

```
redshift-playground/
‚îú‚îÄ‚îÄ README.md                # This file
‚îî‚îÄ‚îÄ redshift-migration/
    ‚îú‚îÄ‚îÄ data-sharing/        # üéØ PRIMARY: Production serverless architecture
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf          # Root module orchestration
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf     # Input variables
    ‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf       # Data sharing commands
    ‚îÇ   ‚îú‚îÄ‚îÄ terraform.tfvars.example # Example configuration
    ‚îÇ   ‚îî‚îÄ‚îÄ modules/         # Terraform modules
    ‚îú‚îÄ‚îÄ traditional/         # üíæ OPTIONAL: For initial data loading only
    ‚îÇ   ‚îú‚îÄ‚îÄ redshift.tf      # Traditional cluster + VPC
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md        # When/why you might need this
    ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars.example
    ‚îú‚îÄ‚îÄ serverless/          # üì¶ DEPRECATED: Use data-sharing instead
    ‚îÇ   ‚îú‚îÄ‚îÄ modules/         # Terraform modules
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ producer/    # Write-optimized namespace
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ consumer/    # Read-optimized workgroups
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ networking/  # VPC, subnets, security
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nlb/        # Network Load Balancer module
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ backend/     # State management
    ‚îÇ   ‚îú‚îÄ‚îÄ backend-setup/   # Remote state infrastructure
    ‚îÇ   ‚îú‚îÄ‚îÄ environments/    # Environment configurations
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dev/        # Development environment
    ‚îÇ   ‚îú‚îÄ‚îÄ test-instance/   # NLB testing infrastructure
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf     # EC2 test instances
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test-*.sh   # Testing scripts
    ‚îÇ   ‚îú‚îÄ‚îÄ scripts/         # Utility scripts
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf          # Root module orchestration
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf     # Input variables
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf       # Data sharing commands
    ‚îú‚îÄ‚îÄ data-generation/     # Mock airline data
    ‚îÇ   ‚îú‚îÄ‚îÄ redshift-airline-schema-fixed.sql
    ‚îÇ   ‚îú‚îÄ‚îÄ generate-airline-data-simple.py
    ‚îÇ   ‚îî‚îÄ‚îÄ setup-schemas.py
    ‚îî‚îÄ‚îÄ docs/                # Extended documentation
        ‚îú‚îÄ‚îÄ connection-guide.md
        ‚îú‚îÄ‚îÄ golden-architecture-patterns.md
        ‚îî‚îÄ‚îÄ migration-strategy.md
```

## Architecture Overview

### Production Architecture (Implemented)

#### Basic Data Sharing Architecture
```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Producer      ‚îÇ
                    ‚îÇ  (Serverless)   ‚îÇ
                    ‚îÇ  Write Ops      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                      Data Sharing
                             ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                         ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Analytics    ‚îÇ      ‚îÇ    Reporting     ‚îÇ
        ‚îÇ   Consumer     ‚îÇ      ‚îÇ    Consumer      ‚îÇ
        ‚îÇ   (Read Only)  ‚îÇ      ‚îÇ    (Read Only)   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Advanced NLB Architecture (Horizontal Scaling)
```
     ETL/Writes ‚îÄ‚îÄ‚îÄ‚îê
                   ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ   Producer      ‚îÇ
          ‚îÇ  (Serverless)   ‚îÇ
          ‚îÇ  32-256 RPUs    ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ Data Sharing
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº        ‚ñº        ‚ñº        ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇConsumer‚îÇ‚îÇConsumer‚îÇ‚îÇConsumer‚îÇ‚îÇConsumer‚îÇ
   ‚îÇ    1   ‚îÇ‚îÇ   2    ‚îÇ‚îÇ   3    ‚îÇ‚îÇ   N    ‚îÇ
   ‚îÇ 32 RPU ‚îÇ‚îÇ 32 RPU ‚îÇ‚îÇ 32 RPU ‚îÇ‚îÇ 32 RPU ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ VPC Endpoints
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ      NLB        ‚îÇ
          ‚îÇ  Load Balancer  ‚îÇ
          ‚îÇ   Port 5439     ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ Read Queries
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ  Applications  ‚îÇ
          ‚îÇ   & BI Tools   ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Note: Producer handles writes directly. NLB only distributes read queries.
```

### Key Components

1. **Producer Namespace** (Write Operations)
   - Serverless: 32-256 RPUs
   - Handles all write operations (ETL, inserts, updates)
   - Owns the source data
   - Manages data sharing permissions

2. **Consumer Namespaces** (Read Operations)
   **Option A: Workload-Specific (Without NLB)**
   - Analytics: 32-128 RPUs for complex queries
   - Reporting: 32-64 RPUs for dashboards
   - Each consumer sized for specific workload
   
   **Option B: Identical Pool (With NLB)**
   - All consumers: Same RPU configuration (e.g., 32-64)
   - Load balancer distributes queries evenly
   - Scale horizontally by adding identical consumers

3. **Data Sharing Benefits**
   - No data movement or copying
   - Real-time data access
   - Independent scaling of read/write workloads
   - Cost isolation between teams/workloads

## üéØ Implementation Status

### ‚úÖ Phase 1: Serverless Architecture
- Standalone data sharing deployment with VPC creation
- Producer namespace for write operations
- Multiple identical consumers for read scaling
- Remote state management with S3/DynamoDB

### ‚úÖ Phase 2: Advanced Features
- Network Load Balancer for horizontal scaling
- Diagnostic tools for monitoring deployments
- Sequential workgroup creation to prevent conflicts
- VPC endpoint support for private connectivity

### ‚úÖ Phase 3: Production Readiness
- Data sharing across namespaces
- Auto-pause for cost optimization
- Health monitoring and diagnostics
- Comprehensive troubleshooting tools

## Quick Start Guide

### Prerequisites
- AWS account with appropriate permissions
- Terraform >= 1.0
- AWS CLI configured
- Python 3.x with psycopg2-binary (only if loading new data)

### Option A: Fresh Deployment (Recommended)

#### 1. Deploy Backend Infrastructure
```bash
cd redshift-migration/data-sharing/backend-setup
terraform init
terraform apply
# Note the output values for backend configuration
```

#### 2. Deploy Data Sharing Architecture
```bash
cd ../
# Copy and update terraform.tfvars
cp terraform.tfvars.example terraform.tfvars
# Edit terraform.tfvars with your IP and password

# Update backend.tf with values from step 1
terraform init
terraform apply
```

#### 3. Restore Existing Snapshot (If Available)
```bash
# If you have a snapshot with data:
# AWS Console ‚Üí Redshift Serverless ‚Üí Producer namespace ‚Üí Restore from snapshot
```

#### 4. Setup Data Sharing
```bash
# Run the SQL commands from terraform output
terraform output data_sharing_commands
```

### Option B: With Initial Data Loading (Traditional)

**Only needed if you don't have a snapshot and need to create sample data**

#### 1. Deploy Traditional Cluster
```bash
cd redshift-migration/traditional
terraform init
terraform apply -var="master_password=YourPassword123!"
```

#### 2. Load Sample Data
```bash
cd ../data-generation
python generate-airline-data-simple.py
```

#### 3. Create Snapshot & Destroy Cluster
```bash
aws redshift create-cluster-snapshot \
  --cluster-identifier my-redshift-cluster \
  --snapshot-identifier airline-data-snapshot

# Destroy traditional cluster to save costs
cd ../traditional
terraform destroy
```

#### 4. Continue with Option A from step 1

## üîë Key Features & Innovations

### Data Model - Airline Star Schema
- **Fact Tables**: 
  - `flight_operations` - Operational metrics (delays, cancellations)
  - `bookings` - Revenue and passenger data
  - `daily_revenue` - Aggregated financial metrics
- **Dimension Tables**:
  - `dim_date` - Time dimension with holiday flags
  - `dim_airport` - Location hierarchy (city, state, country)
  - `dim_aircraft` - Fleet information and capacity
  - `dim_customer` - Passenger demographics
  - `dim_flight` - Route and schedule data
- **Optimization**:
  - Strategic DISTKEY on high-cardinality joins
  - Compound SORTKEY for time-series queries
  - Interleaved SORTKEY for multi-dimensional analysis

### Cost Optimization Strategies
- **Serverless Benefits**:
  - Auto-pause when idle (zero cost during inactivity)
  - Per-second billing for actual usage
  - No over-provisioning required
- **Deployment Strategies**:
  - **Without NLB**: Size consumers for specific workloads (analytics: 128 RPU, reporting: 64 RPU)
  - **With NLB**: Use identical smaller consumers (32-64 RPU each) and scale horizontally
- **Development Options**:
  - Traditional cluster: Fixed $414/month for predictable dev costs
  - Serverless dev: Pay-per-use for sporadic testing

### Security & Compliance
- **Network Security**:
  - VPC isolation with private subnets
  - Security groups with least-privilege rules
  - VPC endpoints for AWS service access
- **Access Control**:
  - IAM roles with fine-grained permissions
  - Database user management with group privileges
  - Data sharing with read-only consumer access
- **Data Protection**:
  - KMS encryption at rest
  - SSL/TLS for data in transit
  - Automated snapshot encryption

## üîß Troubleshooting Guide

### Common Issues & Solutions

1. **"Publicly accessible consumer" error**
   ```sql
   -- On producer namespace
   ALTER DATASHARE airline_share SET PUBLICACCESSIBLE TRUE;
   ```

2. **Insufficient IP addresses**
   - Ensure subnets are /23 or larger (512 IPs minimum)
   - Require 3 subnets in different AZs
   - Each serverless workgroup needs ~32 IPs

3. **Snapshot restore issues**
   - Verify target namespace exists and is active
   - Check IAM role has `redshift:RestoreFromClusterSnapshot`
   - Ensure KMS key policy allows target namespace

4. **NLB connection issues**
   - Verify target group health checks are passing
   - Check security group allows port 5439
   - Ensure VPC endpoints are configured correctly

5. **Data sharing not visible**
   - Wait 2-3 minutes for propagation
   - Verify consumer namespace ID is correct
   - Check datashare is associated with consumer

## Cost Estimates

### Traditional Cluster
- ra3.xlplus: ~$414/month (24/7)
- Best for: Learning, development

### Serverless (Per Namespace)
- Base (32 RPU): $11.52/hour when active
- Scales up to configured maximum
- Auto-pauses when idle
- Best for: Production workloads

### Example Monthly Costs

#### Option A: Workload-Specific (No NLB)
- Producer (32 RPU, 8 hours/day): ~$276/month
- Analytics (64 RPU, 4 hours/day): ~$276/month  
- Reporting (32 RPU, 2 hours/day): ~$69/month
- **Total**: ~$621/month

#### Option B: With NLB (Identical Consumers)
- Producer (32 RPU, 8 hours/day): ~$276/month
- 3x Consumers (32 RPU each, 6 hours/day): ~$621/month
- **Total**: ~$897/month (handles 3x the concurrent queries)

## üìö Lessons Learned

### Infrastructure
1. **VPC Requirements**: 
   - Redshift Serverless requires 3 AZs minimum
   - Use /23 subnets (512 IPs) to avoid IP exhaustion
   - Plan for ~32 IPs per serverless workgroup

2. **Data Sharing Configuration**:
   - Public workgroups need `PUBLICACCESSIBLE TRUE` on datashares
   - Consumer namespaces must be explicitly granted access
   - Cross-namespace queries work immediately after setup

### Development Best Practices
3. **Data Modeling**:
   - Always include primary keys in fact table inserts
   - Use appropriate distribution keys for join performance
   - Consider sort keys based on query patterns

4. **Terraform Organization**:
   - Use remote state (S3 + DynamoDB) for team collaboration
   - Modular design enables environment-specific configurations
   - Separate backend setup prevents circular dependencies

### Performance & Scaling
5. **NLB Testing Results**:
   - Successfully tested load balancing across identical consumers
   - Round-robin distribution works best with same-sized consumers
   - Health checks ensure only active workgroups receive traffic
   - Connection draining prevents query interruption

6. **Cost Management**:
   - Monitor RPU usage to right-size workgroups
   - Use auto-pause aggressively for dev/test environments
   - Consider reserved capacity for predictable workloads

## üöÄ Next Steps & Roadmap

### Phase 4: Production Readiness
- [ ] Implement automated ETL pipelines to producer
- [ ] Set up CloudWatch monitoring and alerting
- [ ] Configure automated backup policies
- [ ] Implement data lifecycle management

### Phase 5: Advanced Features
- [ ] Add cross-region disaster recovery
- [ ] Implement materialized views for performance
- [ ] Set up query monitoring rules (QMR)
- [ ] Create workload management (WLM) queues

### Phase 6: Enterprise Features
- [ ] Integrate with AWS Lake Formation
- [ ] Implement row-level security (RLS)
- [ ] Add data masking for PII
- [ ] Set up cost allocation tags and chargeback

### Phase 7: Optimization
- [ ] Analyze query patterns for further optimization
- [ ] Implement automatic table maintenance
- [ ] Add query result caching strategies
- [ ] Optimize data distribution strategies

## üìñ Additional Resources

### Documentation
- [Connection Guide](redshift-migration/docs/connection-guide.md) - Detailed connection instructions
- [Architecture Patterns](redshift-migration/docs/golden-architecture-patterns.md) - Best practices
- [Migration Strategy](redshift-migration/docs/migration-strategy.md) - Step-by-step migration
- [Data Sharing README](redshift-migration/data-sharing/README.md) - Detailed data sharing setup

### AWS Resources
- [Redshift Serverless Documentation](https://docs.aws.amazon.com/redshift/latest/mgmt/serverless.html)
- [Data Sharing Guide](https://docs.aws.amazon.com/redshift/latest/dg/datashare.html)
- [Best Practices](https://docs.aws.amazon.com/redshift/latest/dg/best-practices.html)

## ü§ù Contributing

Contributions are welcome! Please feel free to submit issues, feature requests, or pull requests.

### Development Setup
1. Fork the repository
2. Create a feature branch
3. Test your changes in dev environment
4. Submit a pull request

## üìÑ License

This is an educational demonstration project. Use at your own risk in production environments.

## üôè Acknowledgments

- AWS Redshift team for excellent documentation
- Terraform community for module patterns
- Contributors and testers